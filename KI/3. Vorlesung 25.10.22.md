### Problem Solving using Search

**Goal-oriented agents**
- Given: initial (World) state
- reach a certain goal
	- goals is certain world state the agent is trying to reach
- using appropriate actions

```ad-note
title: problem formulations:
- representations of world states
- considerable actions
```

#### *Search :* finding the right action sequence to reach the desirable state

- Problem Classification
	1. Single-state Problem
		- complete world and actions knowledge
	2. Multiple-state problem
		- incomplete world knowledge, but complete action  knowledge
	3. Contingency problem
		- incomplete actions knowledge, needs info gathering while running
			- needs a sensor or information gatherer in general
	1. Exploration problem
		- no world and action knowledge 
			- very difficult
			- needs a sensor or niformation gatherer in general


### Terminology:
- *Initial state:*
	- first state, at where the agent starts
- *State space:*
	- set of all possible states
- *Operator:*
	- reachable states from a certain state by an action
- *Successor function S:*
	- S(x), gives the reachable states from a state x
- *Goal test: *
	-  test if a state is a goal state
- *Path:*
	- Sequence of actions
- *Path cost:*
	- Sum of the costs of the actions of the path
- *Solution:*
	- Path that connects initial and goal state
- *Search cost:*
	- Time and memory for finding a solution 
- *Total cost:*
	- Path cost (solution path) + Search cost


```ad-note
title: Choosing a State Space
Abstraction: leave out unnecessary details, choose the most important information
```

#### Search in general:

- Start from inital state
- expand one state (create all succ stats of that state)
	- Search tree (induced by expanding)
	- edges are actions
- Strategie:
	- tells which node to consider next

#### Evaluating Search Strategies:
- Completeness:
	- Does it always work
- Time Complexity:
	- Worst case taken time
- Space Complexity:
	- Worse case taken memory
- Optimality:
	- does it always find the best solution


#### Search Mathods:
1. Uniformed (Blind) Search:
	-  no Information is given about cost and length
2. informed (heurstic) search:
	- With Information about cost and length
	- Greedy search, A*, hill clmbing and simulated annealing


#### Uniformed (Blind) Search:
- breadth-first search:
	- always find the shallowest solution
	- Solutions are optimal, provided all actions have identical non-negative cost
	- Cost is exteremly high
- uniform cost search:
	- always expand in the cheapest way
	- finds the cheapest solution
	- non-negativ action cost
	- Worst case $O(b^{1+\lfloor C^* / \epsilon} \rfloor)$
		- $\epsilon$ cheapst cost
		- C* cost of cheapest solution
- depth-first search:
	- expand each node to the deepst level
	- Worst case: time: $O(b^m)$ Space $(b*m)$
		- b branch factor
		- m: max. depth
		- takes much less space, but still not optimal
- depth-limited search:
	- Same as depth-first, but with a predefinied max. depth
	- maximal known depth (diameter)
- iterative deepening:
	- combines depth - and breadth-first search
	- Optimal and complete, but requires less space
	- Worst case: time: $O(b^d)$ Space $(b*d)$
	- preferred method if search depth unknown!
- bidrectional search:
	- Search in both directions
	- Problems:
		- not always reversible
		- many goal states
		- efficient methods, for when the 2 methods meet
		- Which search method to use , could not always be optimal